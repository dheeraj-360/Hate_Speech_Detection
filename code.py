# -*- coding: utf-8 -*-
"""code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uxm9f0PR9Wlmh-_L_lozIvrC9ia9wECD
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as offen_LANpa
import nltk as offen_LANlln
offen_LANlln.download('stopwords')
import regex as offen_LANrrr
from nltk.corpus import stopwords as offen_LANsttp
from sklearn.feature_extraction.text import TfidfVectorizer as offen_LANidf
import numpy as offen_LANmnn 
from sklearn.model_selection import train_test_split as offen_LANsli

"""*** train, test & valid OLID data"""

offen_LAN_TR = offen_LANpa.read_csv('/content/drive/MyDrive/CE807/Assignment 2/2202392/train.csv')
offen_LAN_TS = offen_LANpa.read_csv('/content/drive/MyDrive/CE807/Assignment 2/2202392/test.csv')
offen_LAN_VL = offen_LANpa.read_csv('/content/drive/MyDrive/CE807/Assignment 2/2202392/valid.csv')

offen_LAN_TR

offen_LAN_TR['label'].value_counts()

offen_LAN_TS

offen_LAN_TS['label'].value_counts()

offen_LAN_VL

offen_LAN_VL['label'].value_counts()

offen_LAN_TR.info()

"""*** Clensing"""

offen_LAN_TR.isna().any()

"""False results shows zero null

*** NLTK feature processing
"""

offen_LANsttp_V = offen_LANsttp.words('english')

def OLID_F(O):                    
    O = O.lower()
    O = offen_LANrrr.sub("[^a-z]+", " ", O)
    O = " ".join([f for f in O.split() if f not in offen_LANsttp_V])
    return O

OLID_vari=[]
for O in offen_LAN_TR['tweet']:
    OLID_vari.append(OLID_F(O))
offen_LAN_TR['tweet']=OLID_vari
offen_LAN_TR['tweet'].head(n=7)

"""** Count Vectorzation"""

offen_LAN_TR_in= offen_LAN_TR['tweet']
offen_LAN_TR_ot= offen_LAN_TR['label']

offen_LANidf_V = offen_LANidf(analyzer='char')
offen_LANidf_V = offen_LANidf_V.fit(offen_LAN_TR_in.apply(lambda ip: offen_LANmnn.str_(ip)))

offen_LANidf_V

## fn to call tfidf vectrzr
def TFIdf(i):
  i = offen_LANidf_V.transform(i.apply(lambda ip: offen_LANmnn.str_(ip)))
  i=i.toarray()
  return i

offen_LAN_TR_in= TFIdf(offen_LAN_TR_in)
offen_LAN_TR_in

"""# **@@ TASK 1: Model Selection @@**"""

#### SVM -First model
from sklearn.svm import SVC as offen_LAN_sv

#### multinomial LR- Second model
from sklearn.linear_model import LogisticRegression as offen_LAN_lr

"""# **@@ TASK 2: Devising and training your own classifier @@**"""

from sklearn.metrics import classification_report as offen_LANcsf
from sklearn.metrics import confusion_matrix as offen_LANoncf
from sklearn import metrics as offen_LANtrm
import joblib as offen_LANbbj

"""### SVM -First model"""

first_mod = offen_LAN_sv() 
first_mod.fit(offen_LAN_TR_in, offen_LAN_TR_ot)

"""extraction of features for validation data using count Vectorizer"""

offen_LAN_VL_in= offen_LAN_VL['tweet']
offen_LAN_VL_in= TFIdf(offen_LAN_VL_in)
print(offen_LAN_VL_in)
offen_LAN_VL_ot= offen_LAN_VL['label']

import warnings as offen_LANWrg
offen_LANWrg.simplefilter("ignore")

offen_LAN_pdr = first_mod.predict(offen_LAN_VL_in)
print(offen_LANcsf(offen_LAN_pdr, offen_LAN_VL_ot))

cmm = offen_LANoncf(offen_LAN_pdr, offen_LAN_VL_ot)
cmm_p=offen_LANtrm.ConfusionMatrixDisplay(confusion_matrix = cmm, display_labels = ['NOT', 'OFF'])
cmm_p.plot()

"""### SVM -First model hypertuning"""

first_mod = offen_LAN_sv(kernel='poly', decision_function_shape='ovr') 
first_mod.fit(offen_LAN_TR_in, offen_LAN_TR_ot)

offen_LAN_pdr = first_mod.predict(offen_LAN_VL_in)
print(offen_LANcsf(offen_LAN_pdr, offen_LAN_VL_ot))

cmm = offen_LANoncf(offen_LAN_pdr, offen_LAN_VL_ot)
cmm_p=offen_LANtrm.ConfusionMatrixDisplay(confusion_matrix = cmm, display_labels = ['NOT', 'OFF'])
cmm_p.plot()

first_mod = offen_LAN_sv(kernel='sigmoid', decision_function_shape='ovo') 
first_mod.fit(offen_LAN_TR_in, offen_LAN_TR_ot)

offen_LAN_pdr = first_mod.predict(offen_LAN_VL_in)
print(offen_LANcsf(offen_LAN_pdr, offen_LAN_VL_ot))

cmm = offen_LANoncf(offen_LAN_pdr, offen_LAN_VL_ot)
cmm_p=offen_LANtrm.ConfusionMatrixDisplay(confusion_matrix = cmm, display_labels = ['NOT', 'OFF'])
cmm_p.plot()

# this is the svm model
first_mod = offen_LAN_sv() 
first_mod.fit(offen_LAN_TR_in, offen_LAN_TR_ot)

"""###  Test the first mod by test data"""

def test_the_md(md):
  offen_LAN_TS_in= offen_LAN_TS['tweet']
  offen_LAN_TS_in= TFIdf(offen_LAN_TS_in)
  offen_LAN_TS_ot= offen_LAN_TS['label']

  offen_LAN_pdr = md.predict(offen_LAN_TS_in)
  print(offen_LANcsf(offen_LAN_pdr, offen_LAN_TS_ot))

  cmm = offen_LANoncf(offen_LAN_pdr, offen_LAN_TS_ot)
  cmm_p=offen_LANtrm.ConfusionMatrixDisplay(confusion_matrix = cmm, display_labels = ['NOT', 'OFF'])
  cmm_p.plot()

  offen_LAN_TS['out_label']=offen_LANpa.DataFrame(offen_LAN_pdr)
  display(offen_LAN_TS)

test_the_md(first_mod)

"""### Multinomial Logistic regression -First model"""

sec_mod = offen_LAN_lr(multi_class='multinomial') 
sec_mod.fit(offen_LAN_TR_in, offen_LAN_TR_ot)

offen_LAN_pdr = sec_mod.predict(offen_LAN_VL_in)
print(offen_LANcsf(offen_LAN_pdr, offen_LAN_VL_ot))

cmm = offen_LANoncf(offen_LAN_pdr, offen_LAN_VL_ot)
cmm_p=offen_LANtrm.ConfusionMatrixDisplay(confusion_matrix = cmm, display_labels = ['NOT', 'OFF'])
cmm_p.plot()

"""### Multinomial LR -second model hypertuning"""

sec_mod = offen_LAN_lr(multi_class='multinomial', solver='sag') 
sec_mod.fit(offen_LAN_TR_in, offen_LAN_TR_ot)

offen_LAN_pdr = sec_mod.predict(offen_LAN_VL_in)
print(offen_LANcsf(offen_LAN_pdr, offen_LAN_VL_ot))

cmm = offen_LANoncf(offen_LAN_pdr, offen_LAN_VL_ot)
cmm_p=offen_LANtrm.ConfusionMatrixDisplay(confusion_matrix = cmm, display_labels = ['NOT', 'OFF'])
cmm_p.plot()

sec_mod = offen_LAN_lr(multi_class='multinomial', solver='saga') 
sec_mod.fit(offen_LAN_TR_in, offen_LAN_TR_ot)

offen_LAN_pdr = sec_mod.predict(offen_LAN_VL_in)
print(offen_LANcsf(offen_LAN_pdr, offen_LAN_VL_ot))

cmm = offen_LANoncf(offen_LAN_pdr, offen_LAN_VL_ot)
cmm_p=offen_LANtrm.ConfusionMatrixDisplay(confusion_matrix = cmm, display_labels = ['NOT', 'OFF'])
cmm_p.plot()

# this is the multinomial Log Regr model
sec_mod = offen_LAN_lr(multi_class='multinomial') 
sec_mod.fit(offen_LAN_TR_in, offen_LAN_TR_ot)

"""###  Test the second mod by test data"""

test_the_md(sec_mod)

"""### first and second model's function"""

#model for svm classifier
def first_md(data):
  offen_LAN_TR_in =data['tweet']
  offen_LAN_TR_in = TFIdf(offen_LAN_TR_in)
  offen_LAN_TR_ot =data['label']

  first_mod= offen_LAN_sv() 
  first_mod.fit(offen_LAN_TR_in, offen_LAN_TR_ot)
  test_the_md(first_mod)

#model for multinomial Log reg classifier
def sec_md(data):
  offen_LAN_TR_in =data['tweet']
  offen_LAN_TR_in = TFIdf(offen_LAN_TR_in)
  offen_LAN_TR_ot =data['label']

  sec_mod = offen_LAN_lr(multi_class='multinomial') 
  sec_mod.fit(offen_LAN_TR_in, offen_LAN_TR_ot)
  test_the_md(sec_mod)

"""# **@@ TASK 3: Data Size Effect @@**

## train tweet data into 4 size [25% & 50% & 75% & 100%]

a) 25% train dataset
"""

tr25 = offen_LANsli(offen_LAN_TR,  random_state=2202392, test_size=0.75) 
train_1= tr25[0]
train_1.shape

offen_LAN_TR_in= TFIdf(train_1['tweet'])

first_md(train_1)
offen_LANbbj.dump(first_mod, '/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/1/25/model.sav')
offen_LANbbj.dump(offen_LAN_TR_in, '/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/1/25/vectorizer.sav')
offen_LAN_TS.to_csv('/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/1/25/output_test.csv', index=False)

sec_md(train_1)
offen_LANbbj.dump(sec_mod, '/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/2/25/model.sav')
offen_LANbbj.dump(offen_LAN_TR_in, '/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/2/25/vectorizer.sav')
offen_LAN_TS.to_csv('/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/2/25/output_test.csv', index=False)

"""b) 50% train dataset"""

tr50 = offen_LANsli(offen_LAN_TR,  random_state=2202392, test_size=0.50)
train_2= tr50[0]
train_2.shape

offen_LAN_TR_in= TFIdf(train_2['tweet'])

first_md(train_2)
offen_LANbbj.dump(first_mod, '/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/1/50/model.sav')
offen_LANbbj.dump(offen_LAN_TR_in, '/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/1/50/vectorizer.sav')
offen_LAN_TS.to_csv('/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/1/50/output_test.csv', index=False)

sec_md(train_2)
offen_LANbbj.dump(sec_mod, '/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/2/50/model.sav')
offen_LANbbj.dump(offen_LAN_TR_in, '/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/2/50/vectorizer.sav')
offen_LAN_TS.to_csv('/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/2/50/output_test.csv', index=False)

"""c) 75% train dataset"""

tr75 = offen_LANsli(offen_LAN_TR,  random_state=2202392, test_size=0.25) 
train_3= tr75[0]
train_3.shape

offen_LAN_TR_in= TFIdf(train_3['tweet'])

first_md(train_3)
offen_LANbbj.dump(first_mod, '/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/1/75/model.sav')
offen_LANbbj.dump(offen_LAN_TR_in, '/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/1/75/vectorizer.sav')
offen_LAN_TS.to_csv('/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/1/75/output_test.csv', index=False)

sec_md(train_3)
offen_LANbbj.dump(sec_mod, '/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/2/75/model.sav')
offen_LANbbj.dump(offen_LAN_TR_in, '/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/2/75/vectorizer.sav')
offen_LAN_TS.to_csv('/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/2/75/output_test.csv', index=False)

"""d) 100% train dataset"""

tr100 = offen_LANsli(offen_LAN_TR,  random_state=2202392, test_size=0.00001) 
train_4= tr100[0]
train_4.shape

offen_LAN_TR_in= TFIdf(train_4['tweet'])

first_md(train_4)
offen_LANbbj.dump(first_mod, '/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/1/100/model.sav')
offen_LANbbj.dump(offen_LAN_TR_in, '/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/1/100/vectorizer.sav')
offen_LAN_TS.to_csv('/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/1/100/output_test.csv', index=False)

sec_md(train_4)
offen_LANbbj.dump(sec_mod, '/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/2/100/model.sav')
offen_LANbbj.dump(offen_LAN_TR_in, '/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/2/100/vectorizer.sav')
offen_LAN_TS.to_csv('/content/drive/MyDrive/CE807/Assignment 2/2202392/Models/2/100/output_test.csv', index=False)

"""validation and testing set performance - first model"""

import matplotlib.pyplot as offen_LAN_mlt

shape_for_val = [offen_LAN_VL.shape[0]]
shape_for_te= [offen_LAN_TS.shape[0]]
acy_for_val = [68]
acy_for_te= [73]

offen_LAN_mlt.scatter(shape_for_val, acy_for_val)
offen_LAN_mlt.scatter(shape_for_te, acy_for_te)
offen_LAN_mlt.legend(["val", "test"], loc='upper right', bbox_to_anchor=(1.4, .65))
offen_LAN_mlt.title('validation and testing set performance - first model')
offen_LAN_mlt.show()

"""accuracy is low for validation data in first model implementation.

validation and testing set performance - second model
"""

acy_for_val = [68]
acy_for_te= [68]

offen_LAN_mlt.scatter(shape_for_val, acy_for_val)
offen_LAN_mlt.scatter(shape_for_te, acy_for_te)
offen_LAN_mlt.legend(["val", "test"], loc='upper right', bbox_to_anchor=(1.3, .65))
offen_LAN_mlt.title('validation and testing set performance - second model')
offen_LAN_mlt.show()

"""Both validation & test data accuracy is equal for in second model implementation.

## Five different offensive language data - Example task
"""

"""the below functions includes all the necessary steps like preprocessing data splitting"""

def percentage(da_fm): 
  SZ= [0.75, 0.50, 0.25, 1]
  for D in SZ:
    da_fme = offen_LANsli(da_fm, test_size= D, random_state=2202392) 
    da_fme= da_fme[0]
    offen_LAN_in= TFIdf(da_fme[da_fme.columns[0]])
    offen_LAN_ot= da_fme[da_fme.columns[1]]
    print(da_fme.shape)
    SVM_M(da_fme)
    LR_M(da_fme)
    print("\n\n")

##  function - preprocess procedure
def nan(da_fm):
  if da_fm.isnull().values.any()==True:
     da_fm=da_fm.dropna()

def repeated(da_fm):
  if da_fm[da_fm.duplicated()].shape[0]==0:
     da_fm=da_fm.drop_duplicates()

def SVM_M(da_fm): # model-1

  from sklearn.metrics import confusion_matrix as offen_LANfucon
  offen_LAN_in= da_fm[da_fm.columns[0]]
  offen_LAN_in= TFIdf(offen_LAN_in)
  offen_LAN_ot= da_fm[da_fm.columns[1]]
  
  offen_LAN_in1, offen_LAN_in2, offen_LAN_ot1, offen_LAN_ot2 = offen_LANsli(offen_LAN_in, offen_LAN_ot, test_size= 0.30, random_state=2202392)
  first_mod = offen_LAN_sv() 
  first_mod.fit(offen_LAN_in1, offen_LAN_ot1)
  
  offen_LAN_pdr = first_mod.predict(offen_LAN_in2)
  print(offen_LANcsf(offen_LAN_pdr, offen_LAN_ot2))
  print(offen_LANoncf(offen_LAN_pdr, offen_LAN_ot2))


def LR_M(da_fm): # model-2

  from sklearn.metrics import confusion_matrix as offen_LANfucon
  offen_LAN_in= da_fm[da_fm.columns[0]]
  offen_LAN_in= TFIdf(offen_LAN_in)
  offen_LAN_ot= da_fm[da_fm.columns[1]]
  offen_LAN_in1, offen_LAN_in2, offen_LAN_ot1, offen_LAN_ot2 = offen_LANsli(offen_LAN_in, offen_LAN_ot, test_size= 0.30, random_state=2202392)

  sec_mod = offen_LAN_lr(multi_class='multinomial') 
  sec_mod.fit(offen_LAN_in1, offen_LAN_ot1)
  
  offen_LAN_pdr = sec_mod.predict(offen_LAN_in2)
  print(offen_LANcsf(offen_LAN_pdr, offen_LAN_ot2))
  print(offen_LANoncf(offen_LAN_pdr, offen_LAN_ot2))

"""Example-1"""

Example1 = offen_LANpa.read_csv('/content/drive/MyDrive/CE807/Assignment 2/2202392/2019-05-28_portuguese_hate_speech_binary_classification.csv')
Example1= Example1[['text', 'hatespeech_comb']]
Example1 = Example1.replace([0, 1],['NOT', 'OFF'])
nan(Example1)
repeated(Example1)
Example1

# calling method-1, 2 for 100% OL_data
SVM_M(Example1)
LR_M(Example1)

# for differnt size of data
percentage(Example1)

"""Example-2"""

Example2 = offen_LANpa.read_csv('/content/drive/MyDrive/CE807/Assignment 2/2202392/XHate999-DE-Wul.txt', delimiter ='\t', encoding='latin-1')
Example2.drop(index=Example2.index[0], axis=0, inplace=True)
Example2 = Example2.replace([0, 1],['NOT', 'OFF'])
nan(Example2)
repeated(Example2)
Example2

# calling method-1, 2 for 100% OL_data
SVM_M(Example2)
LR_M(Example2)

# for differnt size of data
percentage(Example2)

"""Example-3"""

Example3 = offen_LANpa.read_csv('/content/drive/MyDrive/CE807/Assignment 2/2202392/train1.csv')
Example3= Example3[['TEXT', 'label']]
Example3 = Example3.replace([0, 1],['NOT', 'OFF'])
nan(Example3)
repeated(Example3)
Example3

# calling method-1, 2 for 100% OL_data
SVM_M(Example3)
LR_M(Example3)

# for differnt size of data
percentage(Example3)

"""Example-4"""

Example4 = offen_LANpa.read_csv('/content/drive/MyDrive/CE807/Assignment 2/2202392/XHate999-EN-Trac-dev.txt', delimiter ='\t', encoding='latin-1')
Example4 = Example4.replace([0, 1],['NOT', 'OFF'])
nan(Example4)
repeated(Example4)
Example4

# calling method-1, 2 for 100% OL_data
SVM_M(Example4)
LR_M(Example4)

# for differnt size of data
percentage(Example4)

"""Example-5"""

Example5 = offen_LANpa.read_csv('/content/drive/MyDrive/CE807/Assignment 2/2202392/XHate999-SQ-Trac.txt', delimiter ='\t', encoding='latin-1')
Example5 = Example5.replace([0, 1],['NOT', 'OFF'])
nan(Example5)
repeated(Example5)
Example5

# calling method-1, 2 for 100% OL_data
SVM_M(Example5)
LR_M(Example5)

# for differnt size of data
percentage(Example5)